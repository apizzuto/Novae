{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import os, sys, glob, icecube, healpy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import pyplot\n",
    "from icecube import recclasses, dataclasses, dataio, icetray, millipede, gulliver\n",
    "from icecube.recclasses import *\n",
    "from icecube.astro import I3GetEquatorialFromDirection\n",
    "\n",
    "import scipy\n",
    "from scipy import misc, sparse\n",
    "from scipy.stats import chi2, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../numu_pegleg/Nestle_NuMu.140000.000001.000000.i3.bz2\n",
      "5\n",
      "['../numu_pegleg/Nestle_NuMu.140000.000001.000000.i3.bz2', '../numu_pegleg/Nestle_NuMu.140000.000001.000001.i3.bz2', '../numu_pegleg/Nestle_NuMu.140000.000001.000002.i3.bz2', '../numu_pegleg/Nestle_NuMu.140000.000001.000003.i3.bz2', '../numu_pegleg/Nestle_NuMu.140000.000001.000004.i3.bz2']\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob(\"../numu_pegleg/*\")\n",
    "filelist.sort()\n",
    "# Limit this to 20 files by sorting by original\n",
    "# file number\n",
    "filenums = {int(f.split(\".\")[-4]) for f in filelist}\n",
    "by_filenum = []\n",
    "print filelist[0]\n",
    "for n in filenums:\n",
    "    by_filenum.append([f for f in filelist \n",
    "                       if '{:06d}.000'.format(n) in f])\n",
    "    \n",
    "filelist = by_filenum[0][:5]\n",
    "print len(filelist)\n",
    "print filelist\n",
    "\n",
    "nside = 32\n",
    "npix = healpy.nside2npix(nside)\n",
    "hp_xyz = np.array(healpy.pix2vec(nside, np.arange(npix)))\n",
    "hpdec, hpra = healpy.pix2ang(nside, np.arange(npix))\n",
    "zenith, azimuth = np.pi-np.copy(hpdec), np.copy(hpra)\n",
    "hpdec = np.pi/2 - hpdec\n",
    "\n",
    "points = np.zeros((len(zenith), 2), dtype=float)\n",
    "iz, ia = 0, 1\n",
    "points[:,iz] = 0.5*(np.cos(zenith))+0.5\n",
    "points[:,ia] = azimuth / (2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to handle stuff outside of the unit cube...\n",
    "# zenith reflects back while azimuth changes by 1\n",
    "def handle_wrapping(endpoints):\n",
    "    is_outside = (endpoints[:,iz] < 0) \n",
    "    if np.any(is_outside):\n",
    "        endpoints[:,iz][is_outside] *= -1\n",
    "        endpoints[:,ia][is_outside] += 0.5\n",
    "    is_outside = (endpoints[:,iz] >= 1) \n",
    "    if np.any(is_outside):\n",
    "        endpoints[:,iz][is_outside] *= -1\n",
    "        endpoints[:,iz][is_outside] += 2\n",
    "        endpoints[:,ia][is_outside] += 0.5\n",
    "    endpoints[:,ia] %= 1\n",
    "\n",
    "def to_xyz(az, zen):\n",
    "    return np.array([np.cos(az)*np.sin(zen),\n",
    "                     np.sin(az)*np.sin(zen),\n",
    "                     np.cos(zen)])\n",
    "\n",
    "# Define a logsinh function for numerical stability\n",
    "def logsinh(x):\n",
    "    return x - np.log(2) + np.log(1-np.exp(-2*x))\n",
    "    return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(ellipsoids, bf_llh=0, ia=1, iz=0):\n",
    "    kent_sum = np.ones(points.shape[0],dtype=float) * np.inf\n",
    "    for i in range(len(ellipsoids)):\n",
    "        ell = ellipsoids[i]\n",
    "        center = ell.center\n",
    "\n",
    "        dllh = (ell.nllh - bf_llh)\n",
    "\n",
    "        # Okay. Now what?\n",
    "        l, v = np.linalg.eigh(ell.inverse_covariance)\n",
    "        axlens = 1.0/np.sqrt(l)\n",
    "        axes = np.dot(v, np.diag(axlens))\n",
    "\n",
    "        major = axes[:, np.argmax(axlens)]\n",
    "        minor = axes[:, np.argmin(axlens)]\n",
    "\n",
    "        endpoints = np.array([center-major, center-minor])\n",
    "        #endpoints2 = np.array([center+major, center+minor])\n",
    "\n",
    "        handle_wrapping(endpoints)\n",
    "        #handle_wrapping(endpoints2)\n",
    "\n",
    "        # Need to convert the axes coordinates to physical coordinates...\n",
    "        center[ia] *= 2*np.pi\n",
    "        center[iz] = np.pi-np.arccos(2*center[iz]-1)\n",
    "\n",
    "        endpoints[:,ia] *= 2*np.pi\n",
    "        endpoints[:,iz] = np.pi-np.arccos(2*endpoints[:,iz]-1)\n",
    "\n",
    "        #endpoints2[:,ia] *= 2*np.pi\n",
    "        #endpoints2[:,iz] = np.pi-np.arccos(2*endpoints2[:,iz]-1)\n",
    "\n",
    "        center = to_xyz(center[ia], center[iz])\n",
    "        endpoints = np.array([to_xyz(endpoints[0,ia], endpoints[0,iz]),\n",
    "                              to_xyz(endpoints[1,ia], endpoints[1,iz])])\n",
    "        #endpoints2 = np.array([to_xyz(endpoints2[0,ia], endpoints2[0,iz]),\n",
    "        #                      to_xyz(endpoints2[1,ia], endpoints2[1,iz])])\n",
    "\n",
    "        #axis2 = (endpoints[0] - endpoints2[0])/2.\n",
    "        #axis3 = (endpoints[1] - endpoints2[1])/2.\n",
    "        axis2 = endpoints[0] - center\n",
    "        axis3 = endpoints[1] - center\n",
    "        \n",
    "        gamma2_length = np.dot(axis2,axis2)**0.5\n",
    "        gamma3_length = np.dot(axis3,axis3)**0.5\n",
    "        axlens = np.array([gamma2_length, gamma3_length])\n",
    "        if np.any(np.isnan(axlens)): continue    \n",
    "\n",
    "        # I want gamma3 to be the minor axis. Swap them\n",
    "        # if this isn't the case\n",
    "        if gamma2_length < gamma3_length:\n",
    "            tmp = np.copy(axis2)\n",
    "            axis2 = np.copy(axis3)\n",
    "            axis3 = tmp\n",
    "\n",
    "        # We have the kappa value. Let's get the gamma1/2/3\n",
    "        gamma1 = center / np.sqrt(np.sum(center**2))\n",
    "        gamma2 = axis2 / np.sqrt(np.sum(axis2**2))\n",
    "        gamma3 = axis3 / np.sqrt(np.sum(axis3**2))\n",
    "\n",
    "        # The axes were orthogonal in azimuth/coszen, not RA/dec\n",
    "        # The major/minor axes are already orthogonal to the central\n",
    "        # axis, so we just need to project one of them into a third\n",
    "        # axis in order to have \"good\" representation. I'm going to\n",
    "        # just project the minor axis.\n",
    "        g3 = np.cross(gamma1, gamma2)\n",
    "        g3_length = (np.dot(axis3, g3)/(np.dot(g3,g3)**0.5))\n",
    "\n",
    "        axis3 = g3 * g3_length\n",
    "        gamma3 = g3\n",
    "\n",
    "        sigma = np.mean(axlens)\n",
    "        kappa = 1./(sigma)**2\n",
    "        beta = 0.5*kappa * np.sqrt(1-axlens.min()**2/axlens.max()**2)\n",
    "        \n",
    "        # How should we modify the loglikelihood \n",
    "        llh_weight = dllh #+ 2*np.log(1-ell.correlation)\n",
    "\n",
    "        # We now have to calculate the actual llh at each point\n",
    "        # Going to try truncating the constant to just c(0,0)\n",
    "        # Normalization constant:\n",
    "        current_llh = -np.log(kappa)\n",
    "        current_llh += np.log(4*np.pi)\n",
    "        current_llh += logsinh(kappa)\n",
    "\n",
    "        # Shape parameters\n",
    "        current_llh -= kappa*np.dot(gamma1, hp_xyz)\n",
    "        current_llh -= beta*np.dot(gamma2, hp_xyz)**2\n",
    "        current_llh += beta*np.dot(gamma3, hp_xyz)**2\n",
    "        kent_sum = -misc.logsumexp([-kent_sum,\n",
    "                                    -current_llh-llh_weight],axis=0)\n",
    "\n",
    "    return kent_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 5 : ../numu_pegleg/Nestle_NuMu.140000.000001.000000.i3.bz2\n",
      "1 of 5 : ../numu_pegleg/Nestle_NuMu.140000.000001.000001.i3.bz2\n",
      "2 of 5 : ../numu_pegleg/Nestle_NuMu.140000.000001.000002.i3.bz2\n",
      "3 of 5 : ../numu_pegleg/Nestle_NuMu.140000.000001.000003.i3.bz2\n",
      "4 of 5 : ../numu_pegleg/Nestle_NuMu.140000.000001.000004.i3.bz2\n"
     ]
    }
   ],
   "source": [
    "# Build the structures to hold the information I want\n",
    "run = []\n",
    "event = []\n",
    "subevent = []\n",
    "time = []\n",
    "\n",
    "reco_energy = []\n",
    "reco_zenith = []\n",
    "reco_azimuth = []\n",
    "reco_ra = []\n",
    "reco_dec = []\n",
    "\n",
    "llh_map = []\n",
    "\n",
    "# MC Only\n",
    "is_mc = False\n",
    "oneweight = []\n",
    "true_energy = []\n",
    "true_ra = []\n",
    "true_dec = []\n",
    "dllh_truth = []\n",
    "\n",
    "for filenum, infile in enumerate(filelist):\n",
    "    i3file = dataio.I3File(infile, 'r')        \n",
    "    print filenum,'of',len(filelist), ':', infile\n",
    "    eventnum = 0\n",
    "    while i3file.more():\n",
    "        try: frame = i3file.pop_physics()\n",
    "        except: \n",
    "            print(\"Something broke\")\n",
    "            break\n",
    "        \n",
    "        eventnum += 1\n",
    "        \n",
    "        # Event header information\n",
    "        header = frame['I3EventHeader']\n",
    "        run.append(header.run_id)\n",
    "        event.append(header.event_id)\n",
    "        subevent.append(header.sub_event_id)\n",
    "        \n",
    "        t = header.start_time\n",
    "        time.append(t.mod_julian_day_double)\n",
    "\n",
    "        if 'I3MCTree' in frame.keys():\n",
    "            is_mc = True\n",
    "\n",
    "            # Get the information\n",
    "            truth = dataclasses.get_most_energetic_neutrino(frame['I3MCTree'])\n",
    "            mcwd = frame['I3MCWeightDict']\n",
    "            \n",
    "            # Scale by the number of events\n",
    "            ow = mcwd['OneWeight']/mcwd['NEvents']\n",
    "            if 'genie' in infile:\n",
    "                if truth.pdg_encoding > 0: \n",
    "                    ow/=0.7\n",
    "                else: \n",
    "                    ow/=0.3\n",
    "            else:\n",
    "                ow /= 0.5            \n",
    "\n",
    "            # Intentionally not going to scale by\n",
    "            # nfiles here, since I want to do it when\n",
    "            # I merge files. That'll make my life easier\n",
    "            # when I add more files to these.\n",
    "            oneweight.append(ow)\n",
    "            \n",
    "            x = I3GetEquatorialFromDirection(truth.dir, t)\n",
    "            true_ra.append(x.ra)\n",
    "            true_dec.append(x.dec)\n",
    "            true_energy.append(truth.energy)\n",
    "        \n",
    "        # Reconstruction values    \n",
    "        bestfit = frame['Pegleg_Fit_NestleTrack']\n",
    "        \n",
    "        reco_energy.append(bestfit.energy)\n",
    "        reco_zenith.append(bestfit.dir.zenith)\n",
    "        reco_azimuth.append(bestfit.dir.azimuth)\n",
    "\n",
    "        x = I3GetEquatorialFromDirection(bestfit.dir, t)\n",
    "        reco_ra.append(x.ra)\n",
    "        reco_dec.append(x.dec)\n",
    "        \n",
    "        bf_llh = frame['Pegleg_Fit_NestleFitParams'].logl\n",
    "        ellipses = frame['Pegleg_Fit_Nestle_NestleMinimizer']\n",
    "\n",
    "        # Convert the truth into something usable with the ellipsoids\n",
    "        ellipses = ellipses.prune(200)\n",
    "        names = list(ellipses.axis_names)\n",
    "\n",
    "        iz, ia = names.index('Zenith'), names.index('Azimuth')\n",
    "        remove = np.ones(len(names), dtype=bool)\n",
    "        remove[iz] = False\n",
    "        remove[ia] = False\n",
    "        ellipses = ellipses.profile(np.arange(len(names))[remove])\n",
    "        names = list(ellipses.axis_names)\n",
    "        iz, ia = names.index('Zenith'), names.index('Azimuth')\n",
    "        ellipses = [ellipses[i] for i in range(len(ellipses))]\n",
    "        \n",
    "        # Make a map for this event?\n",
    "        kent_sum = get_map(ellipses, bf_llh, ia, iz)\n",
    "        llh_map.append(kent_sum)\n",
    "        \n",
    "        # Where is the truth in this map?\n",
    "        if is_mc:\n",
    "            truth_bin = healpy.ang2pix(nside, np.pi-truth.dir.zenith, truth.dir.azimuth)\n",
    "            dllh = np.max(kent_sum) - kent_sum[truth_bin]\n",
    "            dllh_truth.append(dllh)\n",
    "        \n",
    "        del ellipses        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run      = np.array(run, dtype=int)\n",
    "event    = np.array(event, dtype=int)\n",
    "subevent = np.array(subevent, dtype=int)\n",
    "time     = np.array(time, dtype=float)\n",
    "\n",
    "reco_energy  = np.array(reco_energy, dtype=float)\n",
    "reco_zenith  = np.array(reco_zenith, dtype=float)\n",
    "reco_azimuth = np.array(reco_azimuth, dtype=float)\n",
    "reco_ra  = np.array(reco_ra, dtype=float)\n",
    "reco_dec = np.array(reco_dec, dtype=float)\n",
    "\n",
    "llh_map = np.array(llh_map, dtype=float)\n",
    "\n",
    "if is_mc:\n",
    "    oneweight    = np.array(oneweight, dtype=float)\n",
    "    true_energy  = np.array(true_energy, dtype=float)\n",
    "    true_ra      = np.array(true_ra, dtype=float)\n",
    "    true_dec     = np.array(true_dec, dtype=float)\n",
    "    dllh_truth   = np.array(dllh_truth, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write it out?\n",
    "if is_mc:\n",
    "    datatypes = np.dtype( [ \n",
    "        ('run', np.int64), ('event', np.int64),\n",
    "        ('subevent', np.int64), ('time', np.float64),\n",
    "        ('ra', np.float64), ('dec', np.float64),\n",
    "        ('azi', np.float64), ('zen', np.float64),\n",
    "        ('angErr', np.float64), ('logE', np.float64),\n",
    "        ('trueE', np.float64), ('trueRa', np.float64),\n",
    "        ('trueDec', np.float64), ('ow', np.float64), ],\n",
    "        ('trueDeltaLLH', np.float64))\n",
    "    data = np.array([run, event, subevent, time,\n",
    "                    reco_ra, reco_dec, reco_azimuth, reco_zenith,\n",
    "                    np.zeros_like(reco_zenith), \n",
    "                    np.log10(reco_energy), true_energy,\n",
    "                    true_ra, true_dec, oneweight,\n",
    "                    dllh_truth], datatypes).T\n",
    "else:\n",
    "    datatypes = np.dtype( [ \n",
    "        ('run', np.int64), ('event', np.int64),\n",
    "        ('subevent', np.int64), ('time', np.float64),\n",
    "        ('ra', np.float64), ('dec', np.float64),\n",
    "        ('azi', np.float64), ('zen', np.float64),\n",
    "        ('angErr', np.float64), ('logE', np.float64) ] )\n",
    "    \n",
    "    data = np.array([run, event, subevent, time,\n",
    "                    reco_ra, reco_dec, reco_azimuth, reco_zenith,\n",
    "                    np.zeros_like(reco_zenith), \n",
    "                    np.log10(reco_energy)], datatypes).T\n",
    "    \n",
    "output_name = 'test'\n",
    "print data.dtype.names\n",
    "data = np.rec.array(data, dtype=datatypes)\n",
    "\n",
    "np.save(output_name, data)\n",
    "np.save(output_name+\"_maps\", llh_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
